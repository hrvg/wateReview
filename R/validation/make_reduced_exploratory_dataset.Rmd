---
title: "Make Reduced Exploratory Dataset"
author: Herv√© Guillon
date: June 7, 2019
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r user_functions}
make_pretty_str <- function(string_list){
	# This function takes care of some formatting issue that appeared in the process of aligning database coming from the query and from EndNote.
	# The function removes alpha-numeric characters, some special characters, trim whitespaces and concatenate them.
	# arg in: a list of string
	# output: a cleaned list of string 
	nl <- gsub("[^[:alnum:][:space:]]", "",  string_list)
	nl <- gsub("ltigt", " ",  nl)
	nl <- gsub("\\s+", " ", nl)
	nl <- trimws(nl)
	return(nl)
}
```

```{r reading_data}
english_corpus <- read.csv(file.path("../../data", "english_corpus.csv"))
validation_df_location <- read.csv(file.path("../../data", "validation_df_location.csv"))
```

```{r getting_names}
pdf_names <- lapply(english_corpus$pdfs, function(s){
	ss <- unlist(strsplit(as.character(s), "/"))
	return(ifelse(length(ss) == 1, ss[[1]], ss[[2]]))
})
pdf_names <- make_pretty_str(pdf_names)
validation_titles <- make_pretty_str(validation_df_location$title)
ind <- charmatch(validation_titles, pdf_names, duplicates.ok = TRUE)
```

```{r subsetting_database}
human_read_english_corpus <- english_corpus[na.omit(ind), ]
human_read_english_corpus <- cbind(human_read_english_corpus, validation_df_location[!is.na(ind), -(1:3)])
write.csv(human_read_english_corpus, file.path("../../data", "human_read_english_corpus.csv"), row.names = FALSE)
```