<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ML predictions • wateReview</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="ML predictions">
<meta property="og:description" content="wateReview">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">wateReview</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/wateReview.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Material and methods</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Corpus collection</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/making_query.html">Making the online query</a>
        </li>
        <li>
          <a href="../articles/query_processing.html">Query processing</a>
        </li>
        <li>
          <a href="../articles/query_QA.html">Query QA/QC</a>
        </li>
        <li>
          <a href="../articles/manual_download.html">Manually downloading corpus documents</a>
        </li>
        <li>
          <a href="../articles/select_human_reading.html">Selecting documents for human-reading</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Topic Model</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/topic_model.html">Topic model</a>
        </li>
        <li>
          <a href="../articles/lda_model.html">Running LDA</a>
        </li>
        <li>
          <a href="../articles/get_vocab.html">Getting vocabulary</a>
        </li>
        <li>
          <a href="../articles/lda_vis.html">Visualizing LDA results</a>
        </li>
        <li>
          <a href="../articles/validation.html">Validation</a>
        </li>
        <li>
          <a href="../articles/LDA_comparison.html">Comparing LDA models</a>
        </li>
        <li>
          <a href="../articles/endnote_processing.html">Cross-walk between LDA and EndNote databases</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Metadata mining</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/web_scrapping.html">web_scrapping</a>
        </li>
        <li>
          <a href="../articles/metadata_mining.html">metadata_mining</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Location predictions</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/text_mining.html">text_mining</a>
        </li>
        <li>
          <a href="../articles/webscrapped_training_labels.html">webscrapped_training_labels</a>
        </li>
        <li>
          <a href="../articles/ML_predictions.html">ML_predictions</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Socio-hydrologic clusters</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/clustering_analysis.html">Clustering analysis</a>
        </li>
        <li>
          <a href="../articles/cluster_map.html">Cluster map</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Electronic survey</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/get_emails.html">Mining email addresses</a>
        </li>
        <li>
          <a href="../articles/survey_stats.html">Survey statistics</a>
        </li>
      </ul>
</li>
    <li class="divider">
    <li class="dropdown-header">Analysis</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Research volume</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/timelines.html">Growth through time</a>
        </li>
        <li>
          <a href="../articles/chord_diagrams.html">Chord diagrams</a>
        </li>
        <li>
          <a href="../articles/country_colors.html">Colors of country flags</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Research spread</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/country_entropy.html">Country entropy</a>
        </li>
        <li>
          <a href="../articles/normality.html">Normality</a>
        </li>
        <li>
          <a href="../articles/hexagonal_maps.html">Hexagonal maps</a>
        </li>
      </ul>
</li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Connectivity</a>
      <ul class="dropdown-menu" role="menu">
<li>
          <a href="../articles/citation_network.html">Citation network</a>
        </li>
        <li>
          <a href="../articles/network_visualization.html">Network visualization</a>
        </li>
      </ul>
</li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>ML predictions</h1>
            
      
      
      <div class="hidden name"><code>ML_predictions.Rmd</code></div>

    </div>

    
    
<div id="summary" class="section level2">
<h2 class="hasAnchor">
<a href="#summary" class="anchor"></a>Summary</h2>
</div>
<div id="rationale" class="section level2">
<h2 class="hasAnchor">
<a href="#rationale" class="anchor"></a>Rationale</h2>
<p>The human reading collected metadata about: the document location, the document funding source and the document spatial and temporal scales. I focus here on the identifying scales.</p>
</div>
<div id="problem-definition" class="section level2">
<h2 class="hasAnchor">
<a href="#problem-definition" class="anchor"></a>Problem Definition</h2>
<p>The problem at hand is a classification task. This classification is characterized by having multiple labels. In other words, one document can have the spatial scales labels: “Day” and “Week” and “Year” at the same time. This problem of classification is different of the simpler problem of having to predict one label with different values: a multi-class classification problem. For example, the current problem could be conceptualized as one label “Timescale” taking the values “Day”, “Week”, “Year” and so on.</p>
<p>Two main approaches exist to solve such a multilabel classification problem. The first one is to use algorithm adapted for such a task. The second one is to transform the problem to make it tractable. Such a transformation can be achieved through two schemes: Binary Relevance (BR) and Label Powerset. In the LP approach, the multilabel problem is transformed into a multi-class classification of the labelsets. In the BR approach, the problem is decomposed in a set of binary problems. In addition, we test more refined BR approaches: classifier chains were the binary classifiers are trained in a given order to predict the labels; nested stacking were the labels are approximated successively by learners and dependent binary relevance where every other labels are used as the input for each label-specific binary learners and stacking which combine dependent binary relevance and nested stacking.</p>
<p>The performance metric used is the multilabel Hamming loss corresponding to the proportion of incorrectly predicted labels. We also profide the subset 0 1 metric corresponding to the proportion of observations for which the complete set of label is correctly predicted.</p>
</div>
<div id="temporal-scales" class="section level2">
<h2 class="hasAnchor">
<a href="#temporal-scales" class="anchor"></a>Temporal Scales</h2>
<p>Identifying temporal scales give avenues to</p>
<div id="technical-consideration" class="section level3">
<h3 class="hasAnchor">
<a href="#technical-consideration" class="anchor"></a>Technical consideration</h3>
</div>
</div>
<div id="spatial-scales" class="section level2">
<h2 class="hasAnchor">
<a href="#spatial-scales" class="anchor"></a>Spatial Scales</h2>
</div>
<div id="location-prediction" class="section level1">
<h1 class="hasAnchor">
<a href="#location-prediction" class="anchor"></a>Location Prediction</h1>
<p>Machine learning predicts the location of the country of study of each paper. The training labels were provided by human-reading randomly chosen articles from the corpus (1,428 human-derived labels) and from text mining the article metadata (2,663 text-mined labels). Interestingly, the human-reading provided 563 observations of irrelevant country locations or irrelevant subjects of study.</p>
<p>The human-derived labels are first used for constructing a relevance filter based on simple binary classification between “Relevant” and “Irrelevant” documents (<span class="math inline">\(n = 1,386\)</span>). The predictors consist of the text document term matrix derived from the cleaned corpus text using tokens related to country names and of the topic membership output by the topic model (<span class="math inline">\(p = 138\)</span>). A benchmark of the six following models was conducted: featureless (baseline), random forest, support vector machine, naive Bayes, multinomial regression and extreme gradient boosting. The hyper-parameters are initially set at standard default value. The resampling scheme is 10 repeats of 10-fold cross-validation. The random forest, multinomal and support vector machine models are the best-performing model and show no statistical difference in the distribution of their performance measured by area-under-curve (AUC). These models are selected for further tuning using a nested cross-validation with a simple hold-out inner loop and 10 repeats of 10-fold cross-validation as outer loop. The size of the tuning grid is set to 16 between standard values for each hyper-parameters. Random forest and multinomial are the best-performing tuned models and show no statistical difference in the distribution of their performance measured by AUC. The distribution of the hyper-parameter resulting from the nested cross-validation shows a better constraint for the multinomial model and it is selected for predictions. The performance of such multinomial model corresponds to a mean AUC of 0.82, a mean accuracy of 77% and a true positive rate of 86%.</p>
<p>The prediction of the location of study for each document is performed using both human-derived and text-mined labels (<span class="math inline">\(n = 3,494\)</span>). The predictors consist of the text document term matrix derived from the cleaned corpus text using tokens related to country names (<span class="math inline">\(p = 33\)</span>). Models and resampling scheme are similar than the ones used for the relevance filter. The hyper-parameters are initially set at standard default value. Random forest outperforms every other model with a mean multiclass AUC of 0.99 and a mean accuracy of 96%. No further tuning is performed and the random forest with default hyper-parameters is used for predictions. More complex approaches were investigated: using additional geographical tokens (e.g. rivers and mountain ranges names), multilabel classifications (e.g. binary relevance, label powerset) or deep learning models of natural language processing (e.g. BERT) both on full texts and abstracts with little benefits.</p>
<pre><code><a href="https://rdrr.io/pkg/mlr/man">### libraries
library("mlr")
library("parallelMap")
library("parallel")
library("OpenML")
library("NLP")
library("tm")
library("data.table")
library("mldr")
library("reshape2")
library("ggplot2")
library("rstatix")
library("ggpubr")
library("dplyr")


### utils ###
import::here(.from = "./R/utils/lib_shared.R", 
    get_titleInd,
    get_validationHumanReading,
    get_topicDocs,
    get_titleDocs,
    get_webscrapped_validationDTM,
    get_webscrapped_trainingLabels,
    get_DocTermMatrix,
    align.humanReadingTopicModel,
    QA.alignedData
)

import::here(.from = "./R/utils/lib_ML_predictions.R", 
    make.humanReadingTrainingLabels,
    make.trainingData,
    get.MLDR,
    EDA.trainingData,
    get.binaryRelevanceLearners,
    get.chainingOrder,
    multilabelBenchmark,
    make.task,
    get_short_long_term_pred,
    PerfVisMultilabel,
    make.trainingDataMulticlass,
    multiclassBenchmark,
    make.predictions,
    make.targetData,
    transform.DTM,
    make.AUCPlot,
    get.tuningPar
)

### main

# param
SCALE_TYPE &lt;- "location"
MODEL_TYPE &lt;- "multiclass" # multiclass or binary_relevance
AGGREGATE &lt;- FALSE

# data reading
topicDocs &lt;- get_topicDocs()
titleDocs &lt;- get_titleDocs(topicDocs)
validationHumanReading &lt;-  get_validationHumanReading(scale_type = SCALE_TYPE)
DTM &lt;- get_DocTermMatrix()
webscrapped_validationDTM &lt;- get_webscrapped_validationDTM()
colnames(webscrapped_validationDTM) &lt;- colnames(DTM)
webscrapped_validationDTM &lt;- transform.DTM(webscrapped_validationDTM)
DTM &lt;- transform.DTM(DTM)
webscrapped_trainingLabels &lt;- get_webscrapped_trainingLabels()
titleInd &lt;- get_titleInd(humanReadingDatabase = validationHumanReading, topicModelTitles = titleDocs)

# sanity check
# check if all the papers are found, address issues, align databases
table(is.na(titleInd))
alignedData &lt;- align.humanReadingTopicModel(titleInd, validationHumanReading, topicDocs, DTM)
alignedData &lt;- QA.alignedData(alignedData, scale_type = SCALE_TYPE)
validationTopicDocs &lt;- alignedData$validationTopicDocs
validationHumanReading &lt;- alignedData$validationHumanReading
validationHumanReadingDTM &lt;- alignedData$validationDTM

# get humanReadingTrainingLabels
humanReadingTrainingLabels &lt;- make.humanReadingTrainingLabels(validationHumanReading, scale_type = SCALE_TYPE, webscrapped_trainingLabels)
trainingData &lt;- make.trainingData(validationHumanReadingDTM, humanReadingTrainingLabels, webscrapped_validationDTM, webscrapped_trainingLabels, scale_type = SCALE_TYPE, aggregate_labels = AGGREGATE)

# exploratory data analysis
EDA.trainingData(trainingData, validationHumanReadingDTM, humanReadingTrainingLabels)


cwd_bak &lt;- getwd()
setwd("F:/hguillon/research")

# multilabel: binary relevance and algorithm adaptation

# bmr &lt;- multilabelBenchmark(trainingData, validationHumanReadingDTM, MODEL_TYPE, scale_type = SCALE_TYPE, aggregated_labels = AGGREGATE, obs_threshold = 10)
# AggrPerformances &lt;- getBMRAggrPerformances(bmr, as.df = TRUE)
# PerfVisMultilabel(AggrPerformances)

# multiclass

# ## relevance filter
trainingDataMulticlassFilter &lt;- make.trainingDataMulticlass(trainingData, validationHumanReadingDTM, humanReadingTrainingLabels, webscrapped_validationDTM, webscrapped_trainingLabels, 
    filter = TRUE, 
    addTopicDocs = TRUE, 
    validationTopicDocs = validationTopicDocs)

# ### selecting a model to tune
if (!file.exists("bmr_filter.Rds")){
    bmr_filter &lt;- multiclassBenchmark(trainingDataMulticlassFilter, MODEL_TYPE, filter = TRUE)
    saveRDS(bmr_filter, "bmr_filter.Rds")
} else {
    bmr_filter &lt;- readRDS("bmr_filter.Rds")
}
make.AUCPlot(bmr_filter, binary = TRUE)
# based on the result of the AUC plot comparison, svm, multinom and RF are selected for tuning benchmark

# ### tuning model

if(!file.exists("bmr_tune_filter.Rds")){
    bmr_tune_filter &lt;- multiclassBenchmark(trainingDataMulticlassFilter, MODEL_TYPE, filter = TRUE, tune = list("classif.svm", "classif.randomForest", "classif.multinom"))
    saveRDS(bmr_tune_filter, "bmr_tune_filter.Rds")
} else {
    bmr_tune_filter &lt;- readRDS("bmr_tune_filter.Rds")
}
make.AUCPlot(bmr_tune_filter, binary = TRUE)
# RF and multninomal have similar performance, we pick multinom (better hyper-parameter constrains)

# ### predict
targetData &lt;- make.targetData(DTM, addTopicDocs = TRUE, topicDocs = topicDocs)
predRelevance &lt;- make.predictions("classif.multinom", 
    list(mtry = get.tuningPar(bmr_tune_filter, "decay")),
    trainingDataMulticlassFilter, targetData, MODEL_TYPE, filter = TRUE)
table(predRelevance)

## country
trainingDataMulticlass &lt;- make.trainingDataMulticlass(trainingData, validationHumanReadingDTM, humanReadingTrainingLabels, webscrapped_validationDTM, webscrapped_trainingLabels, filter = FALSE, addWebscrapped = TRUE)

### selecting a model to tune
if (!file.exists("bmr_country.Rds")){
    bmr_country &lt;- multiclassBenchmark(trainingDataMulticlass, MODEL_TYPE, filter = FALSE)
    saveRDS(bmr_country, "bmr_country.Rds")
} else {
    bmr_country &lt;- readRDS("bmr_country.Rds")
}
make.AUCPlot(bmr_country)

# bmr_tune_country &lt;- multiclassBenchmark(trainingDataMulticlass, MODEL_TYPE, filter = FALSE, tune = list("classif.randomForest"))
# make.AUCPlot(bmr_tune_country)
# saveRDS(bmr_tune_country, "bmr_tune_country.Rds")

# ### predict
targetData &lt;- make.targetData(DTM)
predCountry &lt;- make.predictions("classif.randomForest", 
    list(mtry = floor(sqrt(ncol(trainingDataMulticlass) - 1))),
    trainingDataMulticlass, targetData, MODEL_TYPE, filter = FALSE)

predCountry$response &lt;- as.character(predCountry$response)
predCountry$response[as.character(predRelevance) == "Irrelevant"] &lt;- "Irrelevant"
predCountry$response &lt;- as.factor(predCountry$response)

setwd(cwd_bak)

saveRDS(predRelevance, "predRelevance.Rds")
saveRDS(predCountry, "predCountry.Rds")
</a></code></pre>
<pre><code><a href="https://rdrr.io/pkg/mlr/man">### libraries ###
library("mlr")
library("OpenML")
library("NLP")
library("tm")
library("data.table")
library("mldr")
library("dplyr")

### utils ###
import::here(.from = "./R/utils/lib_webscrapping.R",
  make.country_tokens,
  get.EndNoteIdcorpus,
  get.EndNoteIdLDA,
  QA.EndNoteIdCorpusLDA,
  align.dataWithEndNoteIdLDA,
  align.dataWithEndNoteIdcorpus,
  order.data
)

import::here(.from = "./R/utils/lib_ML_predictions.R",
    consolidate_LDA_results,
    make_df_docs
)

# data loading
englishCorpus_file &lt;- "F:/hguillon/research/exploitation/R/latin_america/data/english_corpus.Rds"
englishCorpus &lt;- readRDS(englishCorpus_file)

in_corpus_file &lt;- "in_corpus.Rds"
in_corpus &lt;- readRDS(in_corpus_file)

predCountry &lt;- readRDS("predCountry.Rds") # aligned with englishCorpus
predRelevance &lt;- readRDS("predRelevance.Rds") # aligned with englishCorpus
topicDocs &lt;- readRDS("./data/topicDocs.Rds") # aligned with englishCorpus

# get document IDs
EndNoteIdcorpus &lt;- get.EndNoteIdcorpus(in_corpus)
EndNoteIdLDA &lt;- get.EndNoteIdLDA(englishCorpus)
QA.EndNoteIdCorpusLDA(EndNoteIdLDA, EndNoteIdcorpus)

# align databases 
in_corpus &lt;- align.dataWithEndNoteIdcorpus(in_corpus, EndNoteIdcorpus, EndNoteIdLDA)

englishCorpus &lt;- align.dataWithEndNoteIdLDA(englishCorpus, EndNoteIdLDA, EndNoteIdcorpus)
predCountry &lt;- align.dataWithEndNoteIdLDA(predCountry, EndNoteIdLDA, EndNoteIdcorpus)
predRelevance &lt;- align.dataWithEndNoteIdLDA(predRelevance, EndNoteIdLDA, EndNoteIdcorpus)
topicDocs &lt;- align.dataWithEndNoteIdLDA(topicDocs, EndNoteIdLDA, EndNoteIdcorpus)

EndNoteIdLDA &lt;- align.dataWithEndNoteIdLDA(EndNoteIdLDA, EndNoteIdLDA, EndNoteIdcorpus)
EndNoteIdcorpus &lt;- align.dataWithEndNoteIdcorpus(EndNoteIdcorpus, EndNoteIdcorpus, EndNoteIdLDA)

QA.EndNoteIdCorpusLDA(EndNoteIdLDA, EndNoteIdcorpus)

# order them according to LDA database
in_corpus &lt;- order.data(in_corpus, EndNoteIdLDA, EndNoteIdcorpus)

saveRDS(predRelevance, "predRelevance.Rds")
saveRDS(predCountry %&gt;% pull(response), "predCountry.Rds")
saveRDS(predCountry %&gt;% select(-response), "predCountryMembership.Rds")

consolidate_LDA_results(theme_type = "topic_name", save = TRUE)
consolidate_LDA_results(theme_type = "theme", save = TRUE)
consolidate_LDA_results(theme_type = "NSF_general", save = TRUE)
consolidate_LDA_results(theme_type = "NSF_specific", save = TRUE)
consolidate_LDA_results(theme_type = "theme", description = "water budget", save = TRUE)
consolidate_LDA_results(theme_type = "theme", description = "methods", save = TRUE)
consolidate_LDA_results(theme_type = "theme", description = "spatial scale", save = TRUE)</a></code></pre>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Hervé Guillon, Alyssa DeVincentis, Noelle Patterson, Romina Diaz Gomez, Arthur Koehl.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
