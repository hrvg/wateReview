group_by(value, lang) %>%
tally
View(x2)
######## graphing #############
ggbarplot(x2, x = "value", y = "n",
fill = "lang",
color = "white",
palette = c("#00AFBB", "#FC4E07",  "#E7B800"),
rotate = TRUE)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF general categories",
x = "LDA for each language")+
theme_pubr()
a
plotly::ggplotly(a)
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
######## filter #############
x2 <- x %>%
filter(variable == "NSF_general") %>%
filter(value != "NA") %>%
group_by(value, lang) %>%
tally
## need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
## need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
filter(value != "NA") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
filter(value != "NA") %>%
group_by(value, lang) %>%
tally
View(x2)
# need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
x2 <- na.rm(x2)
View(x)
x <- na.omit(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
#filter(value != "NA") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
x <- rbind(en2,es2,pt2)
x <- na.omit(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
x2 <- na.omit(x2)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
######## filter #############
x2 <- x %>%
filter(variable == "NSF_general") %>%
group_by(value, lang) %>%
tally
library(dplyr)
library(reshape2)
library(ggpubr)
library(tidyr)
library(ggplot2)
######## load data #############
en <- read.csv("./topic_names_en.csv")
es <- read.csv("./topic_names_es.csv")
pt <- read.csv("./topic_names_pt.csv", na.strings=c("","NA"))
en$lang <- "en"
es$lang <- "es"
pt$lang <- "pt"
en2 <- melt(en,
id.vars = c("topic_id","lang"))
es2 <- melt(es,
id.vars = c("topic_id","lang"))
pt2 <- melt(pt,
id.vars = c("topic_id","lang"))
x <- rbind(en2,es2,pt2)
x <- na.omit(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_general") %>%
group_by(value, lang) %>%
tally
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
x2 <- na.omit(x2)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
x2 <- na.omit(x2)
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.97, height=0.97))
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
a <- ggplot(data = x2, aes(x = lang, y = value)) +
geom_tile(aes(fill = n, width=0.9, height=0.9)) # edit for specific vs. general
a
a <- a +
scale_fill_gradient(low = "lightsteelblue1", high = "lightsteelblue4") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language")+
theme_pubr()
a
View(en)
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
################### files #########################
general <- readRDS("./consolidated_results_NSF_general.Rds")
specific <- readRDS("./consolidated_results_NSF_specific.Rds") # 45 themes
methods <- readRDS("./consolidated_results_methods.Rds")
budget <- readRDS("./consolidated_results_water budget.Rds")
theme <- readRDS("./consolidated_results_theme.Rds")
reservoir <- get_JSd_country('reservoirs', plot = T)
# define subset
probs <- reduce_docs_for_JSd(budget)
s
s
s
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
names(sums) = c("country","topic","sum")
df <- sums %>%
group_by(country) %>%
mutate(prop = sum/sum(sum)) %>% # calculate proportion of research each country spends on each topic
group_by(topic) %>%
mutate(scaled = scale(prop)) %>% # scale by topic
ungroup() %>%
select(c("topic","scaled"))
country_distance<- sapply(unique(df$topic), get_JSd_country)
names(country_distance) <- unique(df$topic)
country_distance <- as.data.frame(country_distance)
country_distance$topic <- rownames(country_distance)
df <- probs %>%
mutate(countrytopic = paste(country,topic)) %>%
group_by(countrytopic) %>%
mutate(scaled = scale(value)) %>%
select(c("countrytopic","scaled")) # need to scale somehow?
topic_distance <- sapply(unique(df$countrytopic), get_JSd_corpus)
names(topic_distance) <- unique(df$countrytopic)
topic_distance <- as.data.frame(topic_distance)
topic_distance$countrytopic <- rownames(topic_distance)
topic_distance <- topic_distance %>%
mutate(topic = word(countrytopic, 2, -1)) %>%
group_by(topic) %>%
mutate(topic_distance = median(topic_distance)) %>%
select(c("topic","topic_distance")) %>%
distinct()
################### graph #########################
distance <- merge(country_distance, topic_distance, by = "topic")
################### graph #########################
budget <- merge(country_distance, topic_distance, by = "topic")
write.csv(budget, file = "./diversity/csvs/waterbudgetdistance.csv")
################### pseudocode #########################
# start with 1 topic
# calculate distance from normal distribution for 2 data frames
## 1 - % of research devoted to each topic within a country
## 2- probability of a topic in each document
# subset main df to countries with > 30 papers
# rescale value
# graph density distribution of corpus data + a normal distribution
# extract info both graphs - compare "y"s
# calculate distance - sqrt of JSD
################### code #########################
# define subset
probs <- reduce_docs_for_JSd(budget)
probs <- probs %>% mutate(topic = replace(topic, topic == "groundwater flow", "groundwater"))
############### across countries ###########
# calculate distance from normal for % of research done in each country
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
names(sums) = c("country","topic","sum")
df <- sums %>%
group_by(country) %>%
mutate(prop = sum/sum(sum)) %>% # calculate proportion of research each country spends on each topic
group_by(topic) %>%
mutate(scaled = scale(prop)) %>% # scale by topic
ungroup() %>%
select(c("topic","scaled"))
country_distance<- sapply(unique(df$topic), get_JSd_country)
names(country_distance) <- unique(df$topic)
country_distance <- as.data.frame(country_distance)
country_distance$topic <- rownames(country_distance)
############### across documents ###########
# calculate distance from normal for all documents
# MEDIAN OF JSD for EACH topic by 12 COUNTRIES
df <- probs %>%
mutate(countrytopic = paste(country,topic)) %>%
group_by(countrytopic) %>%
mutate(scaled = scale(value)) %>%
select(c("countrytopic","scaled")) # need to scale somehow?
topic_distance <- sapply(unique(df$countrytopic), get_JSd_corpus)
names(topic_distance) <- unique(df$countrytopic)
topic_distance <- as.data.frame(topic_distance)
topic_distance$countrytopic <- rownames(topic_distance)
topic_distance <- topic_distance %>%
mutate(topic = word(countrytopic, 2, -1)) %>%
group_by(topic) %>%
mutate(topic_distance = median(topic_distance)) %>%
select(c("topic","topic_distance")) %>%
distinct()
################### graph #########################
budget <- merge(country_distance, topic_distance, by = "topic")
write.csv(budget, file = "./diversity/csvs/waterbudgetdistance")
write.csv(budget, file = "./diversity/csvs/waterbudgetdistance.csv")
probs <- reduce_docs_for_JSd(methods)
# probs <- probs %>% mutate(topic = replace(topic, topic == "groundwater flow", "groundwater"))
############### across countries ###########
# calculate distance from normal for % of research done in each country
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
names(sums) = c("country","topic","sum")
df <- sums %>%
group_by(country) %>%
mutate(prop = sum/sum(sum)) %>% # calculate proportion of research each country spends on each topic
group_by(topic) %>%
mutate(scaled = scale(prop)) %>% # scale by topic
ungroup() %>%
select(c("topic","scaled"))
country_distance<- sapply(unique(df$topic), get_JSd_country)
names(country_distance) <- unique(df$topic)
country_distance <- as.data.frame(country_distance)
country_distance$topic <- rownames(country_distance)
############### across documents ###########
# calculate distance from normal for all documents
# MEDIAN OF JSD for EACH topic by 12 COUNTRIES
df <- probs %>%
mutate(countrytopic = paste(country,topic)) %>%
group_by(countrytopic) %>%
mutate(scaled = scale(value)) %>%
select(c("countrytopic","scaled")) # need to scale somehow?
topic_distance <- sapply(unique(df$countrytopic), get_JSd_corpus)
names(topic_distance) <- unique(df$countrytopic)
topic_distance <- as.data.frame(topic_distance)
topic_distance$countrytopic <- rownames(topic_distance)
topic_distance <- topic_distance %>%
mutate(topic = word(countrytopic, 2, -1)) %>%
group_by(topic) %>%
mutate(topic_distance = median(topic_distance)) %>%
select(c("topic","topic_distance")) %>%
distinct()
################### graph #########################
distance <- merge(country_distance, topic_distance, by = "topic")
write.csv(distance, file = "./diversity/csvs/methodsdistance.csv")
budget <- read.csv("./csvs/waterbudgetdistance.csv")
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
budget <- read.csv("./csvs/waterbudgetdistance.csv")
getwd()
budget <- read.csv("./diversity/csvs/waterbudgetdistance.csv")
methods <- read.csv("./diversity/csvs/methodsdistance.csv")
View(budget)
View(methods)
budget <- ggscatter(budget, y = "country_distance", x = "topic_distance",
label = "topic",
label.rectangle = TRUE,
repel = TRUE,
xlab = "Normality across topics",
ylab = "Normality across countries")  # SAVE BUDGET & METHODS SEPARATE
budget
methods <- ggscatter(methods, y = "country_distance", x = "topic_distance",
label = "topic",
label.rectangle = TRUE,
repel = TRUE,
xlab = "Normality across documents",
ylab = "Normality across countries")
methods
methods.edit <-
methods +
theme(axis.text = element_blank()) +
ylim(.58,.92) +
xlim(.25,.63) +
labs(title = "Research methods")
methods.edit <-
methods +
theme(axis.text = element_blank()) +
ylim(.58,.92) +
xlim(.25,.63) +
labs(title = "Research methods")
methods.edi
methods.edit
methods.edit <-
methods +
#theme(axis.text = element_blank()) +
ylim(.58,.92) +
xlim(.25,.63) +
labs(title = "Research methods")
methods.edit
budget.edit <-
budget +
#theme(axis.text = element_blank()) +
ylim(.58,.92) +
xlim(.25,.63) +
labs(title = "Components of water budget")
joined <- ggarrange(budget.edit, methods.edit,
ncol = 2, nrow = 1)
# define subset
probs <- reduce_docs_for_JSd(methods)
budget <- readRDS("./consolidated_results_water budget.Rds")
# define subset
probs <- reduce_docs_for_JSd(methods)
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
# define subset
probs <- reduce_docs_for_JSd(methods)
methods <- readRDS("./consolidated_results_methods.Rds")
# define subset
probs <- reduce_docs_for_JSd(methods)
probs <- probs %>% mutate(topic = replace(topic, topic == "groundwater flow", "groundwater"))
budget <- readRDS("./consolidated_results_water budget.Rds")
# define subset
probs <- reduce_docs_for_JSd(budget)
probs <- probs %>% mutate(topic = replace(topic, topic == "groundwater flow", "groundwater"))
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
names(sums) = c("country","topic","sum")
df <- sums %>%
group_by(country) %>%
mutate(prop = sum/sum(sum)) %>% # calculate proportion of research each country spends on each topic
group_by(topic) %>%
mutate(scaled = scale(prop)) %>% # scale by topic
ungroup() %>%
select(c("topic","scaled"))
reservoir <- get_JSd_country('reservoirs', plot = T)
rivers <- get_JSd_country('rivers', plot = T)
reservoir.edit <-
reservoir +
rremove("legend") +
clean_theme() +
labs(title = "Less normal")
rivers.edit <-
rivers +
rremove("legend") +
ylim(0,0.8) +
clean_theme() +
labs(title = "More normal")
text <- paste("Normality describes how far a topic's distribution is to the standard normal distribution.", sep = " ")
text.p <- ggparagraph(text = text, face = "italic", size = 16, color = "black")
reference2 <- ggarrange(text.p, reservoir.edit, rivers.edit,
ncol = 3, nrow = 1)
reference <- ggarrange(text.p, reservoir.edit, rivers.edit,
ncol = 3, nrow = 1)
ggarrange(reference, joined,
ncol = 1, nrow = 2,
heights = c(1,5))
text <- paste("Normality describes how far a topic's distribution is from the standard normal distribution.", sep = " ")
text.p <- ggparagraph(text = text, face = "italic", size = 16, color = "black")
reference <- ggarrange(text.p, reservoir.edit, rivers.edit,
ncol = 3, nrow = 1)
ggarrange(reference, joined,
ncol = 1, nrow = 2,
heights = c(1,5))
reservoir.edit <-
reservoir +
rremove("legend") +
clean_theme() +
labs(title = "Far from normal")
rivers.edit <-
rivers +
rremove("legend") +
ylim(0,0.8) +
clean_theme() +
labs(title = "Close to normal")
text <- paste("Normality describes how far a topic's distribution is from the standard normal distribution.", sep = " ")
text.p <- ggparagraph(text = text, face = "italic", size = 16, color = "black")
reference <- ggarrange(text.p, reservoir.edit, rivers.edit,
ncol = 3, nrow = 1)
ggarrange(reference, joined,
ncol = 1, nrow = 2,
heights = c(1,5))
