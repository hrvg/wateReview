'plain', 'plain', 'bold', 'bold', 'bold','bold','bold'
))) +
#theme_pubr() +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme(axis.text.y = element_text(face = c('plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'bold', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
#theme_pubr() +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'bold', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
#theme_pubr() +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'bold', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
#theme_pubr() +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
#theme_pubr() +
rremove("legend")
a <- ggplot(data = x2, aes(x = lang, y = fct_reorder(value, nlang))) +
geom_tile(aes(fill = nlang, width=0.9, height=0.9)) +
geom_text(aes(label = n))
a
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
#theme_pubr() +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme_pubr() +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
rremove("legend")
library(dplyr)
library(reshape2)
library(ggpubr)
library(tidyr)
library(ggplot2)
library(forcats)
######## load data #############
en <- read.csv("./topic_names_en.csv")
es <- read.csv("./topic_names_es.csv")
pt <- read.csv("./topic_names_pt.csv", na.strings=c("","NA"))
en$lang <- "en"
es$lang <- "es"
pt$lang <- "pt"
en2 <- melt(en,
id.vars = c("topic_id","lang"))
es2 <- melt(es,
id.vars = c("topic_id","lang"))
pt2 <- melt(pt,
id.vars = c("topic_id","lang"))
x <- rbind(en2,es2,pt2)
x <- na.omit(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers + number of overall topics
x2$nlang <- x2 %>%
group_by(value) %>%
group_map(~ rep(length(table(.x$lang)), length(table(.x$lang)))) %>%
unlist()
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
x2 <- na.omit(x2) # missing 1 spanish?
x2$lang <- factor(x2$lang, labels = c("English", "Spanish", "Portuguese"))
######## heat map #############
a <- ggplot(data = x2, aes(x = lang, y = fct_reorder(value, nlang))) +
geom_tile(aes(fill = nlang, width=0.9, height=0.9)) +
geom_text(aes(label = n))
a
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme_pubr() +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
rremove("legend")
library(dplyr)
library(reshape2)
library(ggpubr)
library(tidyr)
library(ggplot2)
library(forcats)
######## load data #############
en <- read.csv("./topic_names_en.csv")
es <- read.csv("./topic_names_es.csv")
pt <- read.csv("./topic_names_pt.csv", na.strings=c("","NA"))
en$lang <- "en"
es$lang <- "es"
pt$lang <- "pt"
en2 <- melt(en,
id.vars = c("topic_id","lang"))
es2 <- melt(es,
id.vars = c("topic_id","lang"))
pt2 <- melt(pt,
id.vars = c("topic_id","lang"))
x <- rbind(en2,es2,pt2)
x <- na.omit(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers + number of overall topics
x2$nlang <- x2 %>%
group_by(value) %>%
group_map(~ rep(length(table(.x$lang)), length(table(.x$lang)))) %>%
unlist()
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
x2 <- na.omit(x2) # missing 1 spanish?
x2$lang <- factor(x2$lang, labels = c("English", "Spanish", "Portuguese"))
a <- ggplot(data = x2, aes(x = lang, y = fct_reorder(value, nlang))) +
geom_tile(aes(fill = nlang, width=0.9, height=0.9)) +
geom_text(aes(label = n))
a
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "LDA coverage",
y="NSF specific categories",
x = "LDA for each language") +
theme_pubr() +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
rremove("legend")
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "Topic model coverage",
y="NSF specific categories",
x = "Topic model for each language") +
theme_pubr() +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
rremove("legend")
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
library(ggrepel)
################### raw files #########################
general <- readRDS("./consolidated_results_NSF_general.Rds")
specific <- readRDS("./consolidated_results_NSF_specific.Rds") # 45 themes
methods <- readRDS("./consolidated_results_methods.Rds")
budget <- readRDS("./consolidated_results_water budget.Rds")
theme <- readRDS("./consolidated_results_theme.Rds")
# define subset
probs <- reduce_docs_for_JSd(theme)
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
library(ggrepel)
theme <- readRDS("./consolidated_results_theme.Rds")
# define subset
probs <- reduce_docs_for_JSd(theme)
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
View(probs)
names(sums) = c("country","topic","sum")
df <- sums %>%
group_by(country) %>%
mutate(prop = sum/sum(sum)) %>% # calculate proportion of research each country spends on each topic
group_by(topic) %>%
mutate(scaled = scale(prop)) %>% # scale by topic
ungroup() %>%
select(c("topic","scaled"))
country_distance<- sapply(unique(df$topic), get_JSd_country)
names(country_distance) <- unique(df$topic)
country_distance <- as.data.frame(country_distance)
country_distance$topic <- rownames(country_distance)
View(country_distance)
p <- ggplot(subset(df, topic == top)) +
geom_density(aes(x = scaled, y = ..density.., fill= top)) +
xlim(c(-5, 5)) +
stat_function(fun = dnorm, n = 512, args = list(mean = 0, sd = 1)) +
labs(x = "scaled desntiy",
y = "probability of research (rescaled)") +
theme_pubr()
p
View(df)
ggplot(subset(df, topic == "air quality")) +
geom_density(aes(x= scaled, y = ..density.., fill = "air quality")) +
stat_function(fun = dnorm, n = 512, args = list(mean = 0, sd = 1))
ggplot(subset(df, topic == "air quality")) +
geom_density(aes(x= scaled, y = ..density.., fill = "air quality")) +
stat_function(fun = dnorm, n = 512, args = list(mean = 0, sd = 1)) +
xlim(c(-5, 5))
get_JSd_country(air quality)
get_JSd_country(air quality, plot = T)
get_JSd_country("air quality", plot = T)
p <- ggplot(subset(df, topic == "air quality")) +
geom_density(aes(x= scaled, y = ..density.., fill = "air quality")) +
stat_function(fun = dnorm, n = 512, args = list(mean = 0, sd = 1)) +
xlim(c(-5, 5))
p <- ggplot(subset(df, topic == "air quality")) +
geom_density(aes(x= scaled, y = ..density.., fill = "air quality")) +
stat_function(fun = dnorm, n = 512, args = list(mean = 0, sd = 1)) +
xlim(c(-5, 5))
p
g <- ggplot_build(p)
View(g)
View(g)
?ggplot_build
View(g[["data"]][[2]])
View(g[["data"]][[1]])
gdata <- g$data[[1]]$y / sum(g$data[[1]]$y) # topic
normdata <- g$data[[2]]$y / sum(g$data[[2]]$y) # standard, normal
return(1 - sqrt(as.numeric(JSD(rbind(gdata, normdata)))))
sqrt(as.numeric(JSD(rbind(gdata, normdata))))
?JSD
gdata
sums <-aggregate(probs$value, by=list(probs$country,probs$topic), FUN=sum) # re - summarize after removing countries w/ < 30 papers
df <- probs %>%
mutate(countrytopic = paste(country,topic)) %>%
group_by(countrytopic) %>%
mutate(scaled = scale(value)) %>%
select(c("countrytopic","scaled")) # need to scale somehow?
topic_distance <- sapply(unique(df$countrytopic), get_JSd_corpus)
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
library(ggrepel)
################### raw files #########################
general <- readRDS("./consolidated_results_NSF_general.Rds")
specific <- readRDS("./consolidated_results_NSF_specific.Rds") # 45 themes
methods <- readRDS("./consolidated_results_methods.Rds")
budget <- readRDS("./consolidated_results_water budget.Rds")
theme <- readRDS("./consolidated_results_theme.Rds")
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
library(ggrepel)
################### raw files #########################
general <- readRDS("./consolidated_results_NSF_general.Rds")
specific <- readRDS("./consolidated_results_NSF_specific.Rds") # 45 themes
methods <- readRDS("./consolidated_results_methods.Rds")
budget <- readRDS("./consolidated_results_water budget.Rds")
theme <- readRDS("./consolidated_results_theme.Rds")
library(dplyr)
library(reshape2)
library(ggpubr)
library(tidyr)
library(ggplot2)
library(forcats)
######## load data #############
en <- read.csv("./topic_names_en.csv")
es <- read.csv("./topic_names_es.csv")
pt <- read.csv("./topic_names_pt.csv", na.strings=c("","NA"))
library(dplyr)
library(reshape2)
library(ggpubr)
library(tidyr)
library(ggplot2)
library(forcats)
######## load data #############
en <- read.csv("./topic_names_en.csv")
setwd("~/R_code/LAC/diversity")
######## load data #############
en <- read.csv("./topic_names_en.csv")
es <- read.csv("./topic_names_es.csv")
pt <- read.csv("./topic_names_pt.csv", na.strings=c("","NA"))
en$lang <- "en"
es$lang <- "es"
pt$lang <- "pt"
View(en)
en2 <- melt(en,
id.vars = c("topic_id","lang"))
es2 <- melt(es,
id.vars = c("topic_id","lang"))
pt2 <- melt(pt,
id.vars = c("topic_id","lang"))
x <- rbind(en2,es2,pt2)
x <- na.omit(x)
View(x)
######## filter #############
x2 <- x %>%
filter(variable == "NSF_specific") %>%
group_by(value, lang) %>%
tally
# need to order based on engligh numbers + number of overall topics
x2$nlang <- x2 %>%
group_by(value) %>%
group_map(~ rep(length(table(.x$lang)), length(table(.x$lang)))) %>%
unlist()
lvls <- as.character(x2$value[x2$lang=="en"])[order(x2$n[x2$lang=="en"])]
x2$value <- factor(x2$value, levels = lvls)
x2 <- na.omit(x2) # missing 1 spanish?
x2$lang <- factor(x2$lang, labels = c("English", "Spanish", "Portuguese"))
a <- ggplot(data = x2, aes(x = lang, y = fct_reorder(value, nlang))) +
geom_tile(aes(fill = nlang, width=0.9, height=0.9)) +
geom_text(aes(label = n))
a
a +
scale_fill_gradient(low = "grey89",
high = "grey50") +
labs(title= "Topic model coverage",
y="NSF specific categories",
x = "Topic model for each language") +
theme_pubr() +
theme(axis.text.y = element_text(face = c('plain','plain','plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'plain', 'plain', 'plain', 'plain',
'plain', 'bold', 'plain', 'plain', 'plain',
'bold', 'bold', 'plain', 'bold', 'bold',
'bold', 'plain', 'bold','plain', 'plain', # 6-10
'bold', 'bold', 'bold','bold','bold' # 1-5
))) +
rremove("legend")
setwd("~/R_code/LAC")
source("./diversity/lib_lac.R")
################### libraries #########################
library(dplyr)
library(vegan)
library(broom)
library(reshape2)
library(ggpubr)
library(data.table)
library(wesanderson)
library(ggplot2)
library(philentropy)
library(scales)
library(ggplotify)
library(plotly)
library(tidyr)
library(tidyverse)
library(ggrepel)
################### raw files #########################
general <- readRDS("./consolidated_results_NSF_general.Rds")
specific <- readRDS("./consolidated_results_NSF_specific.Rds") # 45 themes
methods <- readRDS("./consolidated_results_methods.Rds")
budget <- readRDS("./consolidated_results_water budget.Rds")
theme <- readRDS("./consolidated_results_theme.Rds")
# calculate diversity by paper / for all of LAC
clean <- remove_year_country(specific) #  specify which (species group)
# calculate diversity by country
general2 <- remove_irrelevant(general)
specific2 <- remove_irrelevant(specific)
theme2 <- remove_irrelevant(theme)
budget2 <- remove_irrelevant(budget)
general2 <-  diversity_country(general2)
specific2 <- diversity_country(specific2)
theme2 <- diversity_country(theme2)
budget2 <- diversity_country(budget2)
warning()
warnings()
budget2 <- diversity_country(budget2)
View(general)
View(general2)
View(budget)
?diversity
